{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):#参考LeNet\n",
    "# TODO:define model\n",
    "    def __init__(self):\n",
    "        super(SimpleNet,self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1,6,3,1,2),nn.ReLU(),nn.MaxPool2d(2,2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(6,16,5),nn.ReLU(),nn.MaxPool2d(2,2))\n",
    "        self.fc1 = nn.Sequential(nn.Linear(400,120),nn.BatchNorm1d(120),nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(120,84),nn.BatchNorm1d(84),nn.ReLU(),nn.Linear(84,10))\n",
    "                                   \n",
    "    def forward(self,input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.conv2(input)\n",
    "        input = input.view(input.size()[0],-1)\n",
    "        input = self.fc1(input)\n",
    "        input = self.fc2(input)\n",
    "        return input\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\python3\\lib\\site-packages\\ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b44a410d37441baacd60f39e04a575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 0\n",
      "Training accuracy: 98.54%\n",
      "Testing accuracy: 98.34%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be6de9cefac49d48072bd807c40d4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Training accuracy: 98.83%\n",
      "Testing accuracy: 98.50%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6b4cc6d674495f93097c1048c6fa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 2\n",
      "Training accuracy: 99.20%\n",
      "Testing accuracy: 98.64%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a309449ff22249e5a47b5258f3f67e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 3\n",
      "Training accuracy: 99.26%\n",
      "Testing accuracy: 98.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f7a102ae86452ebd9c23a4ac810319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 4\n",
      "Training accuracy: 99.36%\n",
      "Testing accuracy: 98.70%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b9fe9c41f7437889d15a851976e015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5\n",
      "Training accuracy: 99.49%\n",
      "Testing accuracy: 98.66%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78abee0e72664af8a093127319de5d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 6\n",
      "Training accuracy: 99.48%\n",
      "Testing accuracy: 98.70%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c5b259ffd4423a95ad89a7385eef5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 7\n",
      "Training accuracy: 99.61%\n",
      "Testing accuracy: 98.86%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989b21ff844a4c29a08c14b728e8f8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 8\n",
      "Training accuracy: 99.64%\n",
      "Testing accuracy: 98.78%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3e1d5a60d242e49abcc1db2a04c8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 9\n",
      "Training accuracy: 99.51%\n",
      "Testing accuracy: 98.52%\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    #model.train()\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # TODO:forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"EPOCH:\",epoch)\n",
    "    #model.eval()\n",
    "    correct_train = 0\n",
    "    correct_test = 0\n",
    "    for images, labels in train_loader:\n",
    "        output = model(images)\n",
    "        predict = torch.max(output.data,1)[1]\n",
    "        correct_train += (predict == labels).sum()\n",
    "    for images, labels in test_loader:\n",
    "        output = model(images)\n",
    "        predict = torch.max(output.data,1)[1]\n",
    "        correct_test += (predict == labels).sum()\n",
    "    train_accuracy = correct_train/len(train_dataset)\n",
    "    test_accuracy = correct_test/len(test_dataset)\n",
    "    print('Training accuracy: %0.2f%%' % (train_accuracy*100))\n",
    "    print('Testing accuracy: %0.2f%%' % (test_accuracy*100))\n",
    "        \n",
    "        \n",
    "        \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
